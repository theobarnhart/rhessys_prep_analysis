{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n",
    "import ipyparallel as p\n",
    "import os\n",
    "import ntpath\n",
    "import ProgressBar as pb\n",
    "from pymail import alert\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "exname = 'smex7_sen'\n",
    "method = '7'\n",
    "site = 'P301'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "files = glob.glob('/Volumes/data/RHESSys_out/P301/'+exname+'/*_basin.daily')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "250000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "params = pd.read_pickle('./data/soil_params_multispinup_%s_smex%s_sen.pcl'%(site,method))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "files = pd.DataFrame({'basin_daily':files})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getIDX(fl):\n",
    "    return int(fl.split('_')[-2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "files['scenidx'] = files.basin_daily.map(getIDX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "params = pd.merge(params,files, on= 'scenidx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from rhessys import snowmelt_experiment as smex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "params['Tnosnow'] = params.TpeakSWE+np.ceil(params.PeakSWE/params.SMR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/barnhatb/Dropbox/python/bin/rhessys/snowmelt_experiment.py:12: FutureWarning: pandas.core.datetools.timedelta is deprecated. Please use datetime.timedelta instead.\n",
      "  td = pd.datetools.timedelta(x.TpeakSWE-1)\n",
      "/Users/barnhatb/Dropbox/python/bin/rhessys/snowmelt_experiment.py:20: FutureWarning: pandas.core.datetools.timedelta is deprecated. Please use datetime.timedelta instead.\n",
      "  td = pd.datetools.timedelta(x.Tnosnow-1)\n"
     ]
    }
   ],
   "source": [
    "params['date_peakSWE'] = params.apply(smex.DOPEAKSWE2cal,axis=1)\n",
    "params['date_ONS'] =params.apply(smex.DONS2cal,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "c = p.Client()\n",
    "view = c.load_balanced_view()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2, 3, 4, 5, 6, 7]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "250000"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dr = pd.date_range('2008-10-1','2009-10-02',freq='D')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%px dr = pd.date_range('2008-10-1','2009-10-02',freq='D')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def processSM(bd,idx,strt,nd):\n",
    "\n",
    "    # read in the basin daily data\n",
    "    data = pd.read_table(bd,delimiter=' ')\n",
    "\n",
    "    data.index = pd.DatetimeIndex(dr)\n",
    "\n",
    "    data['ET'] = data.evap + data.trans\n",
    "\n",
    "    ET = data.ET.sum() # compute total ET\n",
    "    Q = data.streamflow.sum() # compute total streamflow \n",
    "    Qbf = data.baseflow.sum() # compute total baseflow\n",
    "    Qrf = data['return'].sum() # compute total returnflow,p\n",
    "    sm = data.snowmelt.sum()\n",
    "    rech = data.recharge.sum() # compute total recharge\n",
    "    sat = data['%sat_area'].mean() # compute the mean saturated area\n",
    "    p = data.precip.sum() # compute water year precip\n",
    "    rz_storage = data.rz_storage.mean() # root zone storage\n",
    "    rz_drainage = data.rz_drainage.mean() # root zone drainage \n",
    "    unsat_drainage = data.unsat_drain.mean() # unsaturated zone drainage\n",
    "    unsat_storage = data.unsat_stor.mean() # unsaturated zone drainage\n",
    "    sat_def = data.sat_def.mean() # saturation deficite (mm)\n",
    "    sat_def_z = data.sat_def_z.mean() # saturation deficite depth, is this the depth to ground water?\n",
    "    gwStore = data['gw.storage'].sum() # gw store\n",
    "    gwFlux = data['gw.Qout'].mean()\n",
    "    ETRate = data.ET.mean()\n",
    "    \n",
    "    # create full output object\n",
    "    full = (idx,ET,Q,Qbf,Qrf,rech,sat,p,rz_storage,rz_drainage,\n",
    "            unsat_storage,unsat_drainage,sat_def,sat_def_z,sm,gwStore,gwFlux,ETRate)\n",
    "    \n",
    "    data = data.loc[strt:nd] # crop the data to the melt season\n",
    "    \n",
    "    ET = data.ET.sum() # compute total ET\n",
    "    Q = data.streamflow.sum() # compute total streamflow \n",
    "    Qbf = data.baseflow.sum() # compute total baseflow\n",
    "    Qrf = data['return'].sum() # compute total returnflow,p\n",
    "    sm = data.snowmelt.sum()\n",
    "    rech = data.recharge.sum() # compute total recharge\n",
    "    sat = data['%sat_area'].mean() # compute the mean saturated area\n",
    "    p = data.precip.sum() # compute water year precip\n",
    "    rz_storage = data.rz_storage.mean() # root zone storage\n",
    "    rz_drainage = data.rz_drainage.mean() # root zone drainage \n",
    "    unsat_drainage = data.unsat_drain.mean() # unsaturated zone drainage\n",
    "    unsat_storage = data.unsat_stor.mean() # unsaturated zone drainage\n",
    "    sat_def = data.sat_def.mean() # saturation deficite (mm)\n",
    "    sat_def_z = data.sat_def_z.mean() # saturation deficite depth, is this the depth to ground water?\n",
    "    gwStore = data['gw.storage'].sum() # gw store\n",
    "    gwFlux = data['gw.Qout'].mean()\n",
    "    ETRate = data.ET.mean()\n",
    "    \n",
    "    melt = (idx,ET,Q,Qbf,Qrf,rech,sat,p,rz_storage,rz_drainage,\n",
    "            unsat_storage,unsat_drainage,sat_def,sat_def_z,sm,gwStore,gwFlux,ETRate)\n",
    "    \n",
    "    return full,melt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Volumes/data/RHESSys_out/P301/smex7_sen/smex7_sen_0_basin.daily\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((0,\n",
       "  560.4699300000001,\n",
       "  18.431646000000004,\n",
       "  18.431646000000004,\n",
       "  0.0,\n",
       "  362.16081800000006,\n",
       "  0.0,\n",
       "  716.4708499999999,\n",
       "  3250.571043212535,\n",
       "  0.018942937329700274,\n",
       "  1099.9170150381399,\n",
       "  2.1667303760217984,\n",
       "  4947.251389275205,\n",
       "  11372.991699430522,\n",
       "  397.72670499999987,\n",
       "  3807342.9360780073,\n",
       "  0.0,\n",
       "  1.5271660217983654),\n",
       " (0,\n",
       "  15.89281,\n",
       "  2.012645000000001,\n",
       "  2.012645000000001,\n",
       "  0.0,\n",
       "  40.59238799999999,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  3273.973193368419,\n",
       "  0.0,\n",
       "  1097.5065370000004,\n",
       "  0.0,\n",
       "  4930.146548315789,\n",
       "  11333.670225921049,\n",
       "  72.74621599999999,\n",
       "  392564.5292970001,\n",
       "  0.0,\n",
       "  0.41823184210526315))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx = 0\n",
    "print params.basin_daily[idx]\n",
    "processSM(params.basin_daily[idx],params.scenidx[idx],params.date_peakSWE[idx],params.date_ONS[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#res = view.map(processSM,params.basin_daily[0:1000],params.scenidx[0:1000],params.date_peakSWE[0:1000],params.date_ONS[0:1000])\n",
    "res = view.map(processSM,params.basin_daily,params.scenidx,params.date_peakSWE,params.date_ONS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prog = pb.ProgressBar(len(params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "while res.ready() == False:\n",
    "    prog.animate_ipython(res.progress)\n",
    "    time.sleep(2)\n",
    "\n",
    "#alert.send_alert('barnhatb@colorado.edu','Processing Nr1 %s has finished'%exname,'Your script has finished')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.done()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "full,melt = zip(*res.result())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge processing results with parameters dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "idx,ET,Q,Qbf,Qrf,rech,sat,p,rz_storage,rz_drainage,unsat_storage,unsat_drainage,sat_def,sat_def_z,sm,gwStore,gwFlux,ETRate = zip(*full)\n",
    "\n",
    "params = pd.read_pickle('./data/soil_params_multispinup_%s_smex%s_sen.pcl'%(site,method))\n",
    "\n",
    "# make a date frame of the results\n",
    "proc = pd.DataFrame()\n",
    "\n",
    "arrs = [idx,ET,Q,Qbf,Qrf,rech,sat,p,rz_storage,rz_drainage,unsat_storage,unsat_drainage,\n",
    "        sat_def,sat_def_z,sm,gwStore,gwFlux,ETRate]\n",
    "keys = ['scenidx','ET','Q','Qbf','Qrf','rech','sat','p','rz_storage','rz_drainage',\n",
    "        'unsat_storage','unsat_drainage','sat_def','sat_def_z','sm','gwStore','gwFlux','ETRate']\n",
    "\n",
    "for arr,key in zip(arrs,keys):\n",
    "    proc[key] = arr # insert the results\n",
    "\n",
    "params = pd.merge(params,proc,on='scenidx') # join on file index number\n",
    "params.dropna(inplace=True) # drop missing values\n",
    "\n",
    "params.to_hdf('./data/%s_%s_full.hdf'%(site,exname),'df',format='fixed',complevel=5,complib='bzip2',fletcher32=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "idx,ET,Q,Qbf,Qrf,rech,sat,p,rz_storage,rz_drainage,unsat_storage,unsat_drainage,sat_def,sat_def_z,sm,gwStore,gwFlux,ETRate = zip(*melt)\n",
    "\n",
    "params = pd.read_pickle('./data/soil_params_multispinup_%s_smex%s_sen.pcl'%(site,method))\n",
    "\n",
    "# make a date frame of the results\n",
    "proc = pd.DataFrame()\n",
    "\n",
    "arrs = [idx,ET,Q,Qbf,Qrf,rech,sat,p,rz_storage,rz_drainage,unsat_storage,unsat_drainage,\n",
    "        sat_def,sat_def_z,sm,gwStore,gwFlux,ETRate]\n",
    "keys = ['scenidx','ET','Q','Qbf','Qrf','rech','sat','p','rz_storage','rz_drainage',\n",
    "        'unsat_storage','unsat_drainage','sat_def','sat_def_z','sm','gwStore','gwFlux','ETRate']\n",
    "\n",
    "for arr,key in zip(arrs,keys):\n",
    "    proc[key] = arr # insert the results\n",
    "\n",
    "params = pd.merge(params,proc,on='scenidx') # join on file index number\n",
    "params.dropna(inplace=True) # drop missing values\n",
    "\n",
    "params.to_hdf('./data/%s_%s_melt.hdf'%(site,exname),'df',format='fixed',complevel=5,complib='bzip2',fletcher32=True) # "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "alert.send_alert('barnhatb@colorado.edu','Processing P301 %s has finished'%exname,'Your script has finished')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
