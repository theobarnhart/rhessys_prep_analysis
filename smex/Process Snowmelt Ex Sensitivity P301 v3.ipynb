{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n",
    "import ipyparallel as p\n",
    "import os\n",
    "import ntpath\n",
    "import ProgressBar as pb\n",
    "from pymail import alert\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "exname = 'smex8_sen'\n",
    "method = '8'\n",
    "site = 'P301'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = glob.glob('/Volumes/data/RHESSys_out/P301/%s/*_basin.daily'%exname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "150000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = pd.read_pickle('./data/soil_params_multispinup_%s_smex%s_sen.pcl'%(site,method))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params.combo.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MAP</th>\n",
       "      <th>PeakSWE</th>\n",
       "      <th>SMR</th>\n",
       "      <th>TpeakSWE</th>\n",
       "      <th>combo</th>\n",
       "      <th>idx</th>\n",
       "      <th>rd</th>\n",
       "      <th>ref</th>\n",
       "      <th>scenidx</th>\n",
       "      <th>sd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.325</td>\n",
       "      <td>0.521211</td>\n",
       "      <td>0.014403</td>\n",
       "      <td>113.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.011104</td>\n",
       "      <td>2009</td>\n",
       "      <td>0</td>\n",
       "      <td>4.011104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.325</td>\n",
       "      <td>0.521211</td>\n",
       "      <td>0.014403</td>\n",
       "      <td>113.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.111041</td>\n",
       "      <td>2009</td>\n",
       "      <td>1</td>\n",
       "      <td>4.111041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.325</td>\n",
       "      <td>0.521211</td>\n",
       "      <td>0.014403</td>\n",
       "      <td>113.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.222082</td>\n",
       "      <td>2009</td>\n",
       "      <td>2</td>\n",
       "      <td>4.222082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.325</td>\n",
       "      <td>0.521211</td>\n",
       "      <td>0.014403</td>\n",
       "      <td>113.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.444163</td>\n",
       "      <td>2009</td>\n",
       "      <td>3</td>\n",
       "      <td>4.444163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.325</td>\n",
       "      <td>0.521211</td>\n",
       "      <td>0.014403</td>\n",
       "      <td>113.0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0.888326</td>\n",
       "      <td>2009</td>\n",
       "      <td>4</td>\n",
       "      <td>4.888326</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     MAP   PeakSWE       SMR  TpeakSWE  combo  idx        rd   ref  scenidx  \\\n",
       "0  0.325  0.521211  0.014403     113.0      1    0  0.011104  2009        0   \n",
       "1  0.325  0.521211  0.014403     113.0      2    0  0.111041  2009        1   \n",
       "2  0.325  0.521211  0.014403     113.0      3    0  0.222082  2009        2   \n",
       "3  0.325  0.521211  0.014403     113.0      4    0  0.444163  2009        3   \n",
       "4  0.325  0.521211  0.014403     113.0      5    0  0.888326  2009        4   \n",
       "\n",
       "         sd  \n",
       "0  4.011104  \n",
       "1  4.111041  \n",
       "2  4.222082  \n",
       "3  4.444163  \n",
       "4  4.888326  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = pd.DataFrame({'basin_daily':files})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getIDX(fl):\n",
    "    return int(fl.split('_')[-2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "files['scenidx'] = files.basin_daily.map(getIDX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = pd.merge(params,files, on= 'scenidx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rhessys import snowmelt_experiment as smex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "params['Tnosnow'] = params.TpeakSWE+np.ceil(params.PeakSWE/params.SMR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "params['date_peakSWE'] = params.apply(smex.DOPEAKSWE2cal,axis=1)\n",
    "params['date_ONS'] =params.apply(smex.DONS2cal,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = p.Client()\n",
    "view = c.load_balanced_view()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2, 3, 4, 5, 6, 7]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "150000"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "dr = pd.date_range('2008-10-1','2009-10-02',freq='D')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "%px dr = pd.date_range('2008-10-1','2009-10-02',freq='D')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processSM(bd,idx,strt,nd):\n",
    "\n",
    "    # read in the basin daily data\n",
    "    data = pd.read_csv(bd,delimiter=' ')\n",
    "\n",
    "    data.index = pd.DatetimeIndex(dr)\n",
    "\n",
    "    data['ET'] = data.evap + data.trans\n",
    "    trans = data.trans.sum()\n",
    "    evap = data.evap.sum()\n",
    "    sub = data.snow_subl.sum()\n",
    "    ET = data.ET.sum() # compute total ET\n",
    "    PET = data['pet'].sum()\n",
    "    meanPET = data['pet'].mean()\n",
    "    Q = data.streamflow.sum() # compute total streamflow \n",
    "    Qbf = data.baseflow.sum() # compute total baseflow\n",
    "    Qrf = data['return'].sum() # compute total returnflow,p\n",
    "    sm = data.snowmelt.sum()\n",
    "    rech = data.recharge.sum() # compute total recharge\n",
    "    sat = data['%sat_area'].mean() # compute the mean saturated area\n",
    "    p = data.precip.sum() # compute water year precip\n",
    "    rz_storage = data.rz_storage.mean() # root zone storage\n",
    "    rz_drainage = data.rz_drainage.mean() # root zone drainage \n",
    "    unsat_drainage = data.unsat_drain.mean() # unsaturated zone drainage\n",
    "    unsat_storage = data.unsat_stor.mean() # unsaturated zone drainage\n",
    "    sat_def = data.sat_def.mean() # saturation deficite (mm)\n",
    "    sat_def_z = data.sat_def_z.mean() # saturation deficite depth, is this the depth to ground water?\n",
    "    gwStore = data['gw.storage'].sum() # gw store\n",
    "    gwFlux = data['gw.Qout'].mean()\n",
    "    ETRate = data.ET.mean()\n",
    "    \n",
    "    # create full output object\n",
    "    full = (idx,trans,evap,sub,ET,PET,meanPET,Q,Qbf,Qrf,rech,sat,p,rz_storage,rz_drainage,\n",
    "            unsat_storage,unsat_drainage,sat_def,sat_def_z,sm,gwStore,gwFlux,ETRate)\n",
    "    \n",
    "    data = data.loc[strt:nd] # crop the data to the melt season\n",
    "    T = data.trans.sum() # compute totoal transpiration\n",
    "    E = data.evap.sum() # compute total evaporation\n",
    "    sub = data.snow_subl.sum()\n",
    "    ET = data.ET.sum() # compute total ET\n",
    "    PET = data['pet'].sum()\n",
    "    meanPET = data['pet'].mean()\n",
    "    Q = data.streamflow.sum() # compute total streamflow \n",
    "    Qbf = data.baseflow.sum() # compute total baseflow\n",
    "    Qrf = data['return'].sum() # compute total returnflow,p\n",
    "    sm = data.snowmelt.sum()\n",
    "    rech = data.recharge.sum() # compute total recharge\n",
    "    sat = data['%sat_area'].mean() # compute the mean saturated area\n",
    "    p = data.precip.sum() # compute water year precip\n",
    "    rz_storage = data.rz_storage.mean() # root zone storage\n",
    "    rz_drainage = data.rz_drainage.mean() # root zone drainage \n",
    "    unsat_drainage = data.unsat_drain.mean() # unsaturated zone drainage\n",
    "    unsat_storage = data.unsat_stor.mean() # unsaturated zone drainage\n",
    "    sat_def = data.sat_def.mean() # saturation deficite (mm)\n",
    "    sat_def_z = data.sat_def_z.mean() # saturation deficite depth, is this the depth to ground water?\n",
    "    gwStore = data['gw.storage'].sum() # gw store\n",
    "    gwFlux = data['gw.Qout'].mean()\n",
    "    ETRate = data.ET.mean()\n",
    "    \n",
    "    melt = (idx,T,E,sub,ET,PET,meanPET,Q,Qbf,Qrf,rech,sat,p,rz_storage,rz_drainage,\n",
    "            unsat_storage,unsat_drainage,sat_def,sat_def_z,sm,gwStore,gwFlux,ETRate)\n",
    "    \n",
    "    return full,melt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Volumes/data/RHESSys_out/P301/smex8_sen/smex8_sen_0_basin.daily\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((0,\n",
       "  34.84947,\n",
       "  81.803955,\n",
       "  18.039949,\n",
       "  116.653425,\n",
       "  1044.7766889999998,\n",
       "  2.846802967302453,\n",
       "  616.4584530000001,\n",
       "  230.15856499999998,\n",
       "  386.299888,\n",
       "  558.6806300000001,\n",
       "  0.0,\n",
       "  716.4708499999999,\n",
       "  2.2134157356948063,\n",
       "  2.732354108991829,\n",
       "  1941.0120784932024,\n",
       "  4.322964885558577,\n",
       "  1946.6444373569475,\n",
       "  4011.1040799999773,\n",
       "  388.143045,\n",
       "  11673.876054,\n",
       "  0.2587964850136241,\n",
       "  0.3178567438692099),\n",
       " (0,\n",
       "  3.8754020000000002,\n",
       "  5.353626000000001,\n",
       "  5.293211000000001,\n",
       "  9.229027999999998,\n",
       "  33.666386,\n",
       "  0.8859575263157894,\n",
       "  68.89143899999999,\n",
       "  31.740791000000005,\n",
       "  37.15065,\n",
       "  61.962256999999994,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  2.984500210526316,\n",
       "  4.052827631578946,\n",
       "  1942.07875531579,\n",
       "  6.368756921052633,\n",
       "  1946.6443399999994,\n",
       "  4011.10408,\n",
       "  70.650502,\n",
       "  1366.295795,\n",
       "  0.29263349999999994,\n",
       "  0.2428691578947368))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx = 0\n",
    "print params.basin_daily[idx]\n",
    "processSM(params.basin_daily[idx],params.scenidx[idx],params.date_peakSWE[idx],params.date_ONS[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#res = view.map(processSM,params.basin_daily[0:1000],params.scenidx[0:1000],params.date_peakSWE[0:1000],params.date_ONS[0:1000])\n",
    "res = view.map(processSM,params.basin_daily,params.scenidx,params.date_peakSWE,params.date_ONS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "prog = pb.ProgressBar(len(params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[****************100%******************]  149921 of 150000 complete                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   \n"
     ]
    }
   ],
   "source": [
    "while res.ready() == False:\n",
    "    prog.animate_ipython(res.progress)\n",
    "    time.sleep(2)\n",
    "\n",
    "#alert.send_alert('barnhatb@colorado.edu','Processing Nr1 %s has finished'%exname,'Your script has finished')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.done()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "150000"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "full,melt = zip(*res.result())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge processing results with parameters dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx,trans,evap,sub,ET,PET,meanPET,Q,Qbf,Qrf,rech,sat,p,rz_storage,rz_drainage,unsat_storage,unsat_drainage,sat_def,sat_def_z,sm,gwStore,gwFlux,ETRate = zip(*full)\n",
    "\n",
    "params = pd.read_pickle('./data/soil_params_multispinup_%s_smex%s_sen.pcl'%(site,method))\n",
    "\n",
    "# make a date frame of the results\n",
    "proc = pd.DataFrame()\n",
    "\n",
    "arrs = [idx,trans,evap,sub,ET,PET,meanPET,Q,Qbf,Qrf,rech,sat,p,rz_storage,rz_drainage,unsat_storage,unsat_drainage,\n",
    "        sat_def,sat_def_z,sm,gwStore,gwFlux,ETRate]\n",
    "keys = ['scenidx','trans','evap','snow_sub','ET','PET','meanPET','Q','Qbf','Qrf','rech','sat','p','rz_storage','rz_drainage',\n",
    "        'unsat_storage','unsat_drainage','sat_def','sat_def_z','sm','gwStore','gwFlux','ETRate']\n",
    "\n",
    "for arr,key in zip(arrs,keys):\n",
    "    proc[key] = arr # insert the results\n",
    "\n",
    "params = pd.merge(params,proc,on='scenidx') # join on file index number\n",
    "params.dropna(inplace=True) # drop missing values\n",
    "\n",
    "params.to_hdf('./data/%s_%s_full.hdf'%(site,exname),'df',format='fixed',complevel=5,complib='bzip2',fletcher32=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx,T,E,sub,ET,PET,meanPET,Q,Qbf,Qrf,rech,sat,p,rz_storage,rz_drainage,unsat_storage,unsat_drainage,sat_def,sat_def_z,sm,gwStore,gwFlux,ETRate = zip(*melt)\n",
    "\n",
    "params = pd.read_pickle('./data/soil_params_multispinup_%s_smex%s_sen.pcl'%(site,method))\n",
    "\n",
    "# make a date frame of the results\n",
    "proc = pd.DataFrame()\n",
    "\n",
    "arrs = [idx,T,E,sub,ET,PET,meanPET,Q,Qbf,Qrf,rech,sat,p,rz_storage,rz_drainage,unsat_storage,unsat_drainage,\n",
    "        sat_def,sat_def_z,sm,gwStore,gwFlux,ETRate]\n",
    "keys = ['scenidx','T','E','snow_sub','ET','PET','meanPET','Q','Qbf','Qrf','rech','sat','p','rz_storage','rz_drainage',\n",
    "        'unsat_storage','unsat_drainage','sat_def','sat_def_z','sm','gwStore','gwFlux','ETRate']\n",
    "\n",
    "for arr,key in zip(arrs,keys):\n",
    "    proc[key] = arr # insert the results\n",
    "\n",
    "params = pd.merge(params,proc,on='scenidx') # join on file index number\n",
    "params.dropna(inplace=True) # drop missing values\n",
    "\n",
    "params.to_hdf('./data/%s_%s_melt.hdf'%(site,exname),'df',format='fixed',complevel=5,complib='bzip2',fletcher32=True) # "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "alert.send_alert('barnhatb@colorado.edu','Processing P301 %s has finished'%exname,'Your script has finished')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
